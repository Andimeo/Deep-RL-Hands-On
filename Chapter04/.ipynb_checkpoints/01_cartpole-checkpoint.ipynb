{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import gym\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation', 'action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs = env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    while True:\n",
    "        obs_v = torch.FloatTensor([obs])\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        next_obs, reward, is_done, _ = env.step(action)\n",
    "        episode_reward += reward\n",
    "        episode_steps.append(EpisodeStep(observation=obs, action=action))\n",
    "        if is_done:\n",
    "            batch.append(Episode(reward=episode_reward, steps=episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps = []\n",
    "            next_obs = env.reset()\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s: s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward < reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1713,  0.1018], grad_fn=<SelectBackward>)\n",
      "0: loss=0.685, reward_mean=21.4, reward_bound=23.0\n",
      "tensor([-0.0629,  0.0106], grad_fn=<SelectBackward>)\n",
      "1: loss=0.684, reward_mean=26.0, reward_bound=30.0\n",
      "tensor([ 0.1757, -0.2220], grad_fn=<SelectBackward>)\n",
      "2: loss=0.674, reward_mean=29.6, reward_bound=31.5\n",
      "tensor([-0.1719,  0.1378], grad_fn=<SelectBackward>)\n",
      "3: loss=0.664, reward_mean=27.2, reward_bound=30.0\n",
      "tensor([-0.1423,  0.1225], grad_fn=<SelectBackward>)\n",
      "4: loss=0.648, reward_mean=31.4, reward_bound=35.0\n",
      "tensor([ 0.1368, -0.1672], grad_fn=<SelectBackward>)\n",
      "5: loss=0.642, reward_mean=31.7, reward_bound=31.0\n",
      "tensor([-0.4163,  0.3337], grad_fn=<SelectBackward>)\n",
      "6: loss=0.640, reward_mean=28.1, reward_bound=31.5\n",
      "tensor([-0.5708,  0.4719], grad_fn=<SelectBackward>)\n",
      "7: loss=0.628, reward_mean=31.4, reward_bound=31.0\n",
      "tensor([-0.2206,  0.1622], grad_fn=<SelectBackward>)\n",
      "8: loss=0.610, reward_mean=39.7, reward_bound=46.0\n",
      "tensor([-0.4820,  0.4414], grad_fn=<SelectBackward>)\n",
      "9: loss=0.612, reward_mean=42.8, reward_bound=54.5\n",
      "tensor([-0.4475,  0.3898], grad_fn=<SelectBackward>)\n",
      "10: loss=0.616, reward_mean=45.3, reward_bound=59.0\n",
      "tensor([ 0.1765, -0.1267], grad_fn=<SelectBackward>)\n",
      "11: loss=0.591, reward_mean=37.5, reward_bound=41.5\n",
      "tensor([ 0.4200, -0.4082], grad_fn=<SelectBackward>)\n",
      "12: loss=0.588, reward_mean=52.1, reward_bound=59.0\n",
      "tensor([-0.9414,  0.8985], grad_fn=<SelectBackward>)\n",
      "13: loss=0.577, reward_mean=46.4, reward_bound=54.0\n",
      "tensor([ 0.9705, -1.0316], grad_fn=<SelectBackward>)\n",
      "14: loss=0.582, reward_mean=57.0, reward_bound=65.5\n",
      "tensor([ 0.6036, -0.6172], grad_fn=<SelectBackward>)\n",
      "15: loss=0.567, reward_mean=51.9, reward_bound=60.5\n",
      "tensor([ 0.2954, -0.3571], grad_fn=<SelectBackward>)\n",
      "16: loss=0.558, reward_mean=59.8, reward_bound=67.5\n",
      "tensor([ 0.0212, -0.0652], grad_fn=<SelectBackward>)\n",
      "17: loss=0.544, reward_mean=62.9, reward_bound=68.5\n",
      "tensor([-0.2058,  0.2172], grad_fn=<SelectBackward>)\n",
      "18: loss=0.550, reward_mean=54.8, reward_bound=60.5\n",
      "tensor([-0.8214,  0.8190], grad_fn=<SelectBackward>)\n",
      "19: loss=0.572, reward_mean=62.3, reward_bound=69.5\n",
      "tensor([ 1.4359, -1.5655], grad_fn=<SelectBackward>)\n",
      "20: loss=0.544, reward_mean=62.4, reward_bound=67.0\n",
      "tensor([-0.0542, -0.0034], grad_fn=<SelectBackward>)\n",
      "21: loss=0.526, reward_mean=66.4, reward_bound=86.5\n",
      "tensor([ 0.1383, -0.0941], grad_fn=<SelectBackward>)\n",
      "22: loss=0.545, reward_mean=70.4, reward_bound=72.0\n",
      "tensor([-1.0105,  1.0035], grad_fn=<SelectBackward>)\n",
      "23: loss=0.525, reward_mean=65.8, reward_bound=76.0\n",
      "tensor([-0.7577,  0.7298], grad_fn=<SelectBackward>)\n",
      "24: loss=0.522, reward_mean=82.2, reward_bound=87.5\n",
      "tensor([-0.6078,  0.5286], grad_fn=<SelectBackward>)\n",
      "25: loss=0.519, reward_mean=71.5, reward_bound=76.5\n",
      "tensor([-0.5771,  0.4754], grad_fn=<SelectBackward>)\n",
      "26: loss=0.544, reward_mean=67.8, reward_bound=77.0\n",
      "tensor([-1.0495,  1.0043], grad_fn=<SelectBackward>)\n",
      "27: loss=0.503, reward_mean=74.1, reward_bound=70.0\n",
      "tensor([ 1.0538, -1.0347], grad_fn=<SelectBackward>)\n",
      "28: loss=0.521, reward_mean=72.9, reward_bound=89.0\n",
      "tensor([ 1.5601, -1.5762], grad_fn=<SelectBackward>)\n",
      "29: loss=0.558, reward_mean=86.4, reward_bound=112.5\n",
      "tensor([-0.7295,  0.6583], grad_fn=<SelectBackward>)\n",
      "30: loss=0.527, reward_mean=85.4, reward_bound=96.5\n",
      "tensor([ 0.4358, -0.3398], grad_fn=<SelectBackward>)\n",
      "31: loss=0.496, reward_mean=92.1, reward_bound=98.0\n",
      "tensor([ 0.4099, -0.3619], grad_fn=<SelectBackward>)\n",
      "32: loss=0.498, reward_mean=103.9, reward_bound=135.0\n",
      "tensor([-0.6327,  0.5874], grad_fn=<SelectBackward>)\n",
      "33: loss=0.514, reward_mean=92.1, reward_bound=97.0\n",
      "tensor([ 0.1908, -0.2161], grad_fn=<SelectBackward>)\n",
      "34: loss=0.507, reward_mean=93.6, reward_bound=100.5\n",
      "tensor([-0.4945,  0.5567], grad_fn=<SelectBackward>)\n",
      "35: loss=0.487, reward_mean=92.0, reward_bound=89.0\n",
      "tensor([ 1.7482, -1.7775], grad_fn=<SelectBackward>)\n",
      "36: loss=0.507, reward_mean=110.7, reward_bound=115.5\n",
      "tensor([ 0.7043, -0.6928], grad_fn=<SelectBackward>)\n",
      "37: loss=0.512, reward_mean=113.9, reward_bound=140.5\n",
      "tensor([-0.0929,  0.1223], grad_fn=<SelectBackward>)\n",
      "38: loss=0.511, reward_mean=113.4, reward_bound=133.0\n",
      "tensor([ 0.9132, -0.8237], grad_fn=<SelectBackward>)\n",
      "39: loss=0.504, reward_mean=108.9, reward_bound=111.0\n",
      "tensor([-0.4411,  0.4341], grad_fn=<SelectBackward>)\n",
      "40: loss=0.497, reward_mean=131.9, reward_bound=155.0\n",
      "tensor([ 0.5495, -0.6005], grad_fn=<SelectBackward>)\n",
      "41: loss=0.518, reward_mean=174.9, reward_bound=197.0\n",
      "tensor([-0.2644,  0.3029], grad_fn=<SelectBackward>)\n",
      "42: loss=0.508, reward_mean=148.1, reward_bound=189.0\n",
      "tensor([-0.1696,  0.1875], grad_fn=<SelectBackward>)\n",
      "43: loss=0.507, reward_mean=148.9, reward_bound=185.5\n",
      "tensor([-1.1887,  0.8219], grad_fn=<SelectBackward>)\n",
      "44: loss=0.496, reward_mean=160.8, reward_bound=196.5\n",
      "tensor([-0.8447,  0.7948], grad_fn=<SelectBackward>)\n",
      "45: loss=0.503, reward_mean=159.1, reward_bound=196.5\n",
      "tensor([ 0.1628, -0.0278], grad_fn=<SelectBackward>)\n",
      "46: loss=0.511, reward_mean=170.8, reward_bound=200.0\n",
      "tensor([ 0.3517, -0.5272], grad_fn=<SelectBackward>)\n",
      "47: loss=0.512, reward_mean=177.1, reward_bound=200.0\n",
      "tensor([-0.0801,  0.0834], grad_fn=<SelectBackward>)\n",
      "48: loss=0.509, reward_mean=172.3, reward_bound=200.0\n",
      "tensor([ 0.1342, -0.0033], grad_fn=<SelectBackward>)\n",
      "49: loss=0.497, reward_mean=181.1, reward_bound=200.0\n",
      "tensor([ 0.2949, -0.2132], grad_fn=<SelectBackward>)\n",
      "50: loss=0.501, reward_mean=190.4, reward_bound=200.0\n",
      "tensor([ 1.4755, -1.5064], grad_fn=<SelectBackward>)\n",
      "51: loss=0.505, reward_mean=196.1, reward_bound=200.0\n",
      "tensor([-0.4466,  0.3918], grad_fn=<SelectBackward>)\n",
      "52: loss=0.512, reward_mean=196.2, reward_bound=200.0\n",
      "tensor([-0.2562,  0.2594], grad_fn=<SelectBackward>)\n",
      "53: loss=0.517, reward_mean=200.0, reward_bound=200.0\n",
      "Solved!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    # env = gym.wrappers.Monitor(env, directory=\"mon\", force=True)\n",
    "    obs_size = env.observation_space.shape[0]\n",
    "    n_actions = env.action_space.n\n",
    "    net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=net.parameters(), lr=0.01)\n",
    "    writer = SummaryWriter(comment=\"-cartpole\")\n",
    "    for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "        obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "        optimizer.zero_grad()\n",
    "        action_scores_v = net(obs_v)\n",
    "        print(action_scores_v[-1])\n",
    "        loss_v = objective(action_scores_v, acts_v)\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (\n",
    "            iter_no, loss_v.item(), reward_m, reward_b))\n",
    "        writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "        writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "        writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "        if reward_m > 199:\n",
    "            print(\"Solved!\")\n",
    "            break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_size = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment='-cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0695, -0.1390], grad_fn=<SelectBackward>)\n",
      "0: loss=0.658, reward_mean=44.1, reward_bound=51.5\n",
      "tensor([-0.1373, -0.0831], grad_fn=<SelectBackward>)\n",
      "1: loss=0.642, reward_mean=40.1, reward_bound=53.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-d7feb28b120a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reward_bound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reward_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rl/lib/python3.5/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_caffe2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mscalar_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         self.file_writer.add_summary(\n\u001b[0m\u001b[1;32m    342\u001b[0m             scalar(tag, scalar_value), global_step, walltime)\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_summary'"
     ]
    }
   ],
   "source": [
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, acts_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print('%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f' % (iter_no, loss_v.item(), reward_m, reward_b))\n",
    "    writer.add_scalar('loss', loss_v.item(), iter_no)\n",
    "    writer.add_scalar('reward_bound', reward_b, iter_no)\n",
    "    writer.add_scalar('reward_mean', reward_m, iter_no)\n",
    "    if reward_m > 199:\n",
    "        print('Solved!')\n",
    "        break\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iterate_batches(env, net, BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 22, 23, 29, 19, 14, 19, 16, 11, 14, 13, 48, 18, 18, 15, 19]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(episode.steps) for episode in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpisodeStep(observation=array([-0.03168259, -0.0100702 , -0.04541047, -0.01882977]), action=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_v, acts_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.1875"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_scores_v = net(obs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8778e-02, -2.5827e-01],\n",
       "        [ 3.0591e-02, -2.5549e-01],\n",
       "        [ 4.2970e-02, -2.4724e-01],\n",
       "        [ 3.3381e-02, -2.5624e-01],\n",
       "        [ 4.7873e-02, -2.4821e-01],\n",
       "        [ 3.7356e-02, -2.5711e-01],\n",
       "        [ 3.2863e-02, -2.6265e-01],\n",
       "        [ 3.6673e-02, -2.7144e-01],\n",
       "        [ 2.7418e-02, -3.0114e-01],\n",
       "        [ 4.0055e-02, -2.7342e-01],\n",
       "        [ 3.9951e-02, -2.6921e-01],\n",
       "        [ 4.2385e-02, -2.7519e-01],\n",
       "        [ 3.5282e-02, -3.0086e-01],\n",
       "        [ 4.5142e-02, -2.7707e-01],\n",
       "        [ 4.6143e-02, -2.7359e-01],\n",
       "        [ 6.1927e-02, -2.6329e-01],\n",
       "        [ 7.3979e-02, -2.4938e-01],\n",
       "        [ 8.1344e-02, -2.3165e-01],\n",
       "        [ 5.4716e-02, -2.3900e-01],\n",
       "        [ 1.1416e-02, -2.5906e-01],\n",
       "        [ 6.9206e-02, -2.4053e-01],\n",
       "        [ 1.9792e-02, -2.6152e-01],\n",
       "        [ 3.0258e-02, -2.6217e-01],\n",
       "        [ 2.3561e-02, -2.5878e-01],\n",
       "        [ 2.9174e-02, -2.4855e-01],\n",
       "        [ 4.1717e-02, -2.3846e-01],\n",
       "        [ 3.0388e-02, -2.4831e-01],\n",
       "        [ 4.4765e-02, -2.3817e-01],\n",
       "        [ 3.3141e-02, -2.4855e-01],\n",
       "        [ 4.9485e-02, -2.3768e-01],\n",
       "        [ 3.7935e-02, -2.4970e-01],\n",
       "        [ 2.7958e-02, -2.5941e-01],\n",
       "        [ 3.1223e-02, -2.6220e-01],\n",
       "        [ 3.0891e-02, -2.7659e-01],\n",
       "        [ 3.4512e-02, -2.6472e-01],\n",
       "        [ 3.9666e-02, -2.6337e-01],\n",
       "        [ 3.6930e-02, -2.6729e-01],\n",
       "        [ 4.5867e-02, -2.6447e-01],\n",
       "        [ 6.3631e-02, -2.5459e-01],\n",
       "        [ 5.3256e-02, -2.6576e-01],\n",
       "        [ 7.4030e-02, -2.5593e-01],\n",
       "        [ 8.5608e-02, -2.3532e-01],\n",
       "        [ 7.1943e-02, -2.2940e-01],\n",
       "        [ 1.0092e-01, -2.3679e-01],\n",
       "        [ 1.0758e-01, -2.5708e-01],\n",
       "        [ 3.7301e-02, -2.6335e-01],\n",
       "        [ 3.3637e-02, -2.8111e-01],\n",
       "        [ 3.2519e-02, -3.1820e-01],\n",
       "        [ 3.1588e-02, -2.8209e-01],\n",
       "        [ 3.2446e-02, -2.6125e-01],\n",
       "        [ 2.8918e-02, -2.8294e-01],\n",
       "        [ 3.1177e-02, -3.1970e-01],\n",
       "        [ 2.6385e-02, -2.8574e-01],\n",
       "        [ 2.3794e-02, -2.5915e-01],\n",
       "        [ 9.4989e-03, -2.5438e-01],\n",
       "        [ 1.8925e-02, -2.5825e-01],\n",
       "        [ 5.2773e-03, -2.5196e-01],\n",
       "        [ 7.5642e-03, -2.4286e-01],\n",
       "        [ 1.4788e-02, -2.3418e-01],\n",
       "        [ 1.9512e-03, -2.4238e-01],\n",
       "        [ 9.9170e-03, -2.3132e-01],\n",
       "        [-2.2047e-03, -2.4169e-01],\n",
       "        [ 6.3029e-03, -2.2874e-01],\n",
       "        [ 2.2237e-02, -2.2530e-01],\n",
       "        [ 1.1424e-02, -2.1876e-01],\n",
       "        [-1.9795e-02, -2.2847e-01],\n",
       "        [ 2.3458e-02, -2.1275e-01],\n",
       "        [-7.5314e-03, -2.2081e-01],\n",
       "        [-5.0013e-02, -2.3105e-01],\n",
       "        [ 6.2901e-03, -2.1367e-01],\n",
       "        [ 4.0774e-02, -2.1074e-01],\n",
       "        [ 1.6894e-02, -2.0955e-01],\n",
       "        [-2.6843e-02, -2.2102e-01],\n",
       "        [-7.2033e-02, -2.4034e-01],\n",
       "        [ 3.2827e-02, -2.6726e-01],\n",
       "        [ 3.1527e-02, -2.6282e-01],\n",
       "        [ 3.3198e-02, -2.6754e-01],\n",
       "        [ 3.2662e-02, -2.6347e-01],\n",
       "        [ 4.0431e-02, -2.5386e-01],\n",
       "        [ 5.1708e-02, -2.3885e-01],\n",
       "        [ 4.6679e-02, -2.5517e-01],\n",
       "        [ 5.7880e-02, -2.3896e-01],\n",
       "        [ 5.5963e-02, -2.5735e-01],\n",
       "        [ 6.7388e-02, -2.3821e-01],\n",
       "        [ 6.8572e-02, -2.5993e-01],\n",
       "        [ 5.8296e-02, -2.7319e-01],\n",
       "        [ 4.7185e-02, -2.8443e-01],\n",
       "        [ 6.9849e-02, -2.7613e-01],\n",
       "        [ 5.4897e-02, -2.9165e-01],\n",
       "        [ 5.4729e-02, -2.9048e-01],\n",
       "        [ 6.5709e-02, -2.9364e-01],\n",
       "        [ 1.0003e-01, -2.7754e-01],\n",
       "        [ 8.0508e-02, -2.9361e-01],\n",
       "        [ 3.6249e-02, -2.6289e-01],\n",
       "        [ 3.1804e-02, -2.8249e-01],\n",
       "        [ 3.5733e-02, -2.6256e-01],\n",
       "        [ 3.1041e-02, -2.8286e-01],\n",
       "        [ 3.4968e-02, -2.6215e-01],\n",
       "        [ 3.0001e-02, -2.8340e-01],\n",
       "        [ 3.3767e-02, -2.6141e-01],\n",
       "        [ 2.3657e-02, -2.5821e-01],\n",
       "        [ 3.0561e-02, -2.4692e-01],\n",
       "        [ 4.3475e-02, -2.3874e-01],\n",
       "        [ 3.0566e-02, -2.4604e-01],\n",
       "        [ 4.5926e-02, -2.3892e-01],\n",
       "        [ 5.2306e-02, -2.2123e-01],\n",
       "        [ 2.7036e-02, -2.2793e-01],\n",
       "        [-1.9443e-02, -2.4469e-01],\n",
       "        [ 4.0599e-02, -2.2302e-01],\n",
       "        [ 7.3471e-02, -2.1886e-01],\n",
       "        [ 4.9178e-02, -2.2243e-01],\n",
       "        [ 1.5381e-03, -2.4165e-01],\n",
       "        [ 4.3043e-02, -2.6629e-01],\n",
       "        [ 4.0332e-02, -2.8362e-01],\n",
       "        [ 3.4625e-02, -3.2044e-01],\n",
       "        [ 3.9434e-02, -2.8428e-01],\n",
       "        [ 3.5279e-02, -3.2160e-01],\n",
       "        [ 3.7458e-02, -2.8451e-01],\n",
       "        [ 3.5926e-02, -3.2203e-01],\n",
       "        [ 4.2279e-02, -3.6463e-01],\n",
       "        [ 3.7416e-02, -3.2278e-01],\n",
       "        [ 3.2558e-02, -2.8807e-01],\n",
       "        [ 3.0213e-02, -2.6283e-01],\n",
       "        [ 1.6513e-02, -2.5692e-01],\n",
       "        [ 2.1324e-02, -2.4526e-01],\n",
       "        [ 1.1647e-02, -2.5486e-01],\n",
       "        [ 2.0707e-02, -2.6020e-01],\n",
       "        [ 7.7804e-03, -2.5294e-01],\n",
       "        [ 1.5542e-02, -2.5872e-01],\n",
       "        [ 3.7540e-03, -2.5084e-01],\n",
       "        [ 1.5187e-03, -2.4365e-01],\n",
       "        [ 7.0223e-03, -2.3108e-01],\n",
       "        [ 1.9258e-02, -2.2635e-01],\n",
       "        [ 2.8040e-03, -2.2806e-01],\n",
       "        [-9.7581e-03, -2.4038e-01],\n",
       "        [-9.4660e-04, -2.2621e-01],\n",
       "        [ 1.4188e-02, -2.2432e-01],\n",
       "        [-4.3899e-03, -2.2524e-01],\n",
       "        [ 1.2175e-02, -2.2196e-01],\n",
       "        [-7.3248e-03, -2.2374e-01],\n",
       "        [-1.4639e-02, -2.3403e-01],\n",
       "        [-8.0902e-03, -2.2256e-01],\n",
       "        [-1.4575e-02, -2.3284e-01],\n",
       "        [-8.1977e-03, -2.2134e-01],\n",
       "        [-1.3901e-02, -2.3182e-01],\n",
       "        [-7.7579e-03, -2.2018e-01],\n",
       "        [ 1.3788e-02, -2.1464e-01],\n",
       "        [ 2.6488e-02, -2.1017e-01],\n",
       "        [ 1.6526e-02, -2.1205e-01],\n",
       "        [ 3.0661e-02, -2.0833e-01],\n",
       "        [ 2.2678e-02, -2.1003e-01],\n",
       "        [ 1.6132e-03, -2.1732e-01],\n",
       "        [ 3.2288e-02, -2.0875e-01],\n",
       "        [ 1.0264e-02, -2.1806e-01],\n",
       "        [ 4.2402e-02, -2.0878e-01],\n",
       "        [ 2.1521e-02, -2.1889e-01],\n",
       "        [ 5.2889e-02, -2.0921e-01],\n",
       "        [ 5.9857e-02, -2.0631e-01],\n",
       "        [ 4.0242e-02, -2.0172e-01],\n",
       "        [-4.2736e-03, -2.1324e-01],\n",
       "        [ 2.3942e-02, -2.6029e-01],\n",
       "        [ 1.8292e-02, -2.5711e-01],\n",
       "        [ 2.2927e-02, -2.5870e-01],\n",
       "        [ 2.3142e-02, -2.7781e-01],\n",
       "        [ 2.1384e-02, -2.5788e-01],\n",
       "        [ 2.2025e-02, -2.7883e-01],\n",
       "        [ 2.4219e-02, -3.1280e-01],\n",
       "        [ 3.0872e-02, -3.6043e-01],\n",
       "        [ 2.6230e-02, -3.1576e-01],\n",
       "        [ 1.6642e-02, -2.8338e-01],\n",
       "        [ 8.4392e-03, -2.5631e-01],\n",
       "        [ 1.0171e-02, -2.8034e-01],\n",
       "        [ 3.1854e-03, -2.5553e-01],\n",
       "        [-1.1537e-02, -2.4719e-01],\n",
       "        [-3.7330e-03, -2.5355e-01],\n",
       "        [ 3.1184e-04, -2.7654e-01],\n",
       "        [ 1.1552e-02, -3.2687e-01],\n",
       "        [ 1.6915e-02, -3.8256e-01],\n",
       "        [ 3.4449e-02, -4.4062e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_scores_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_probs_v = sm(action_scores_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5713, 0.4287],\n",
       "        [0.5710, 0.4290],\n",
       "        [0.5720, 0.4280],\n",
       "        [0.5719, 0.4281],\n",
       "        [0.5735, 0.4265],\n",
       "        [0.5731, 0.4269],\n",
       "        [0.5733, 0.4267],\n",
       "        [0.5764, 0.4236],\n",
       "        [0.5814, 0.4186],\n",
       "        [0.5777, 0.4223],\n",
       "        [0.5767, 0.4233],\n",
       "        [0.5787, 0.4213],\n",
       "        [0.5833, 0.4167],\n",
       "        [0.5799, 0.4201],\n",
       "        [0.5793, 0.4207],\n",
       "        [0.5806, 0.4194],\n",
       "        [0.5801, 0.4199],\n",
       "        [0.5776, 0.4224],\n",
       "        [0.5729, 0.4271],\n",
       "        [0.5672, 0.4328],\n",
       "        [0.5768, 0.4232],\n",
       "        [0.5699, 0.4301],\n",
       "        [0.5726, 0.4274],\n",
       "        [0.5701, 0.4299],\n",
       "        [0.5690, 0.4310],\n",
       "        [0.5696, 0.4304],\n",
       "        [0.5692, 0.4308],\n",
       "        [0.5703, 0.4297],\n",
       "        [0.5700, 0.4300],\n",
       "        [0.5713, 0.4287],\n",
       "        [0.5714, 0.4286],\n",
       "        [0.5714, 0.4286],\n",
       "        [0.5728, 0.4272],\n",
       "        [0.5763, 0.4237],\n",
       "        [0.5743, 0.4257],\n",
       "        [0.5752, 0.4248],\n",
       "        [0.5755, 0.4245],\n",
       "        [0.5770, 0.4230],\n",
       "        [0.5789, 0.4211],\n",
       "        [0.5791, 0.4209],\n",
       "        [0.5818, 0.4182],\n",
       "        [0.5796, 0.4204],\n",
       "        [0.5748, 0.4252],\n",
       "        [0.5836, 0.4164],\n",
       "        [0.5902, 0.4098],\n",
       "        [0.5746, 0.4254],\n",
       "        [0.5780, 0.4220],\n",
       "        [0.5868, 0.4132],\n",
       "        [0.5778, 0.4222],\n",
       "        [0.5729, 0.4271],\n",
       "        [0.5773, 0.4227],\n",
       "        [0.5868, 0.4132],\n",
       "        [0.5774, 0.4226],\n",
       "        [0.5703, 0.4297],\n",
       "        [0.5656, 0.4344],\n",
       "        [0.5689, 0.4311],\n",
       "        [0.5640, 0.4360],\n",
       "        [0.5623, 0.4377],\n",
       "        [0.5619, 0.4381],\n",
       "        [0.5608, 0.4392],\n",
       "        [0.5600, 0.4400],\n",
       "        [0.5596, 0.4404],\n",
       "        [0.5585, 0.4415],\n",
       "        [0.5616, 0.4384],\n",
       "        [0.5573, 0.4427],\n",
       "        [0.5520, 0.4480],\n",
       "        [0.5588, 0.4412],\n",
       "        [0.5531, 0.4469],\n",
       "        [0.5451, 0.4549],\n",
       "        [0.5548, 0.4452],\n",
       "        [0.5625, 0.4375],\n",
       "        [0.5564, 0.4436],\n",
       "        [0.5484, 0.4516],\n",
       "        [0.5420, 0.4580],\n",
       "        [0.5745, 0.4255],\n",
       "        [0.5731, 0.4269],\n",
       "        [0.5746, 0.4254],\n",
       "        [0.5735, 0.4265],\n",
       "        [0.5730, 0.4270],\n",
       "        [0.5721, 0.4279],\n",
       "        [0.5749, 0.4251],\n",
       "        [0.5737, 0.4263],\n",
       "        [0.5777, 0.4223],\n",
       "        [0.5758, 0.4242],\n",
       "        [0.5814, 0.4186],\n",
       "        [0.5821, 0.4179],\n",
       "        [0.5822, 0.4178],\n",
       "        [0.5856, 0.4144],\n",
       "        [0.5858, 0.4142],\n",
       "        [0.5855, 0.4145],\n",
       "        [0.5889, 0.4111],\n",
       "        [0.5933, 0.4067],\n",
       "        [0.5925, 0.4075],\n",
       "        [0.5742, 0.4258],\n",
       "        [0.5779, 0.4221],\n",
       "        [0.5740, 0.4260],\n",
       "        [0.5778, 0.4222],\n",
       "        [0.5737, 0.4263],\n",
       "        [0.5777, 0.4223],\n",
       "        [0.5733, 0.4267],\n",
       "        [0.5700, 0.4300],\n",
       "        [0.5689, 0.4311],\n",
       "        [0.5701, 0.4299],\n",
       "        [0.5687, 0.4313],\n",
       "        [0.5707, 0.4293],\n",
       "        [0.5680, 0.4320],\n",
       "        [0.5634, 0.4366],\n",
       "        [0.5561, 0.4439],\n",
       "        [0.5655, 0.4345],\n",
       "        [0.5726, 0.4274],\n",
       "        [0.5675, 0.4325],\n",
       "        [0.5605, 0.4395],\n",
       "        [0.5767, 0.4233],\n",
       "        [0.5803, 0.4197],\n",
       "        [0.5878, 0.4122],\n",
       "        [0.5802, 0.4198],\n",
       "        [0.5883, 0.4117],\n",
       "        [0.5798, 0.4202],\n",
       "        [0.5885, 0.4115],\n",
       "        [0.6003, 0.3997],\n",
       "        [0.5891, 0.4109],\n",
       "        [0.5795, 0.4205],\n",
       "        [0.5727, 0.4273],\n",
       "        [0.5679, 0.4321],\n",
       "        [0.5663, 0.4337],\n",
       "        [0.5662, 0.4338],\n",
       "        [0.5698, 0.4302],\n",
       "        [0.5648, 0.4352],\n",
       "        [0.5681, 0.4319],\n",
       "        [0.5633, 0.4367],\n",
       "        [0.5610, 0.4390],\n",
       "        [0.5592, 0.4408],\n",
       "        [0.5611, 0.4389],\n",
       "        [0.5575, 0.4425],\n",
       "        [0.5574, 0.4426],\n",
       "        [0.5561, 0.4439],\n",
       "        [0.5593, 0.4407],\n",
       "        [0.5550, 0.4450],\n",
       "        [0.5583, 0.4417],\n",
       "        [0.5539, 0.4461],\n",
       "        [0.5546, 0.4454],\n",
       "        [0.5534, 0.4466],\n",
       "        [0.5544, 0.4456],\n",
       "        [0.5531, 0.4469],\n",
       "        [0.5543, 0.4457],\n",
       "        [0.5529, 0.4471],\n",
       "        [0.5569, 0.4431],\n",
       "        [0.5589, 0.4411],\n",
       "        [0.5569, 0.4431],\n",
       "        [0.5595, 0.4405],\n",
       "        [0.5579, 0.4421],\n",
       "        [0.5545, 0.4455],\n",
       "        [0.5600, 0.4400],\n",
       "        [0.5568, 0.4432],\n",
       "        [0.5625, 0.4375],\n",
       "        [0.5598, 0.4402],\n",
       "        [0.5652, 0.4348],\n",
       "        [0.5662, 0.4338],\n",
       "        [0.5602, 0.4398],\n",
       "        [0.5521, 0.4479],\n",
       "        [0.5706, 0.4294],\n",
       "        [0.5684, 0.4316],\n",
       "        [0.5699, 0.4301],\n",
       "        [0.5747, 0.4253],\n",
       "        [0.5694, 0.4306],\n",
       "        [0.5747, 0.4253],\n",
       "        [0.5835, 0.4165],\n",
       "        [0.5966, 0.4034],\n",
       "        [0.5847, 0.4153],\n",
       "        [0.5744, 0.4256],\n",
       "        [0.5658, 0.4342],\n",
       "        [0.5721, 0.4279],\n",
       "        [0.5643, 0.4357],\n",
       "        [0.5586, 0.4414],\n",
       "        [0.5621, 0.4379],\n",
       "        [0.5688, 0.4312],\n",
       "        [0.5838, 0.4162],\n",
       "        [0.5986, 0.4014],\n",
       "        [0.6166, 0.3834]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_probs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5712733 , 0.42872667], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_probs_v.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
